{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2805b-3af3-4b8c-8ea9-91abddea168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spam Email Detection using Logistic Regression\n",
    "# Mini Project Implementation\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Download NLTK data (run once)\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')\n",
    "\n",
    "class SpamDetector:\n",
    "    def __init__(self):\n",
    "        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        self.model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "        self.stop_words = set(stopwords.words('english'))\n",
    "        \n",
    "    def preprocess_text(self, text):\n",
    "        \"\"\"\n",
    "        Comprehensive text preprocessing function\n",
    "        \"\"\"\n",
    "        # Convert to lowercase\n",
    "        text = str(text).lower()\n",
    "        \n",
    "        # Remove URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # Remove email addresses\n",
    "        text = re.sub(r'\\S+@\\S+', '', text)\n",
    "        \n",
    "        # Remove numbers\n",
    "        text = re.sub(r'\\d+', '', text)\n",
    "        \n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        text = ' '.join(text.split())\n",
    "        \n",
    "        # Tokenize and remove stopwords\n",
    "        tokens = word_tokenize(text)\n",
    "        tokens = [token for token in tokens if token not in self.stop_words and len(token) > 2]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def load_and_prepare_data(self, file_path=None, use_sample=True):\n",
    "        \"\"\"\n",
    "        Load and prepare the dataset\n",
    "        If use_sample=True, creates a sample dataset for demonstration\n",
    "        \"\"\"\n",
    "        if use_sample or file_path is None:\n",
    "            # Create a sample dataset for demonstration\n",
    "            sample_data = {\n",
    "                'text': [\n",
    "                    \"Congratulations! You've won $1000! Click here to claim your prize now!\",\n",
    "                    \"Hi, let's meet for coffee tomorrow at 3pm\",\n",
    "                    \"URGENT: Your account will be suspended. Verify now!\",\n",
    "                    \"Thanks for the meeting today. Here are the notes we discussed\",\n",
    "                    \"FREE VIAGRA! No prescription needed! Order now!\",\n",
    "                    \"Can you send me the report by end of day?\",\n",
    "                    \"WINNER! You are selected for a cash prize of $5000!\",\n",
    "                    \"Happy birthday! Hope you have a wonderful day\",\n",
    "                    \"CHEAP LOANS! Apply now for instant approval!\",\n",
    "                    \"Reminder: Team meeting scheduled for tomorrow at 10am\",\n",
    "                    \"Make money fast! Work from home opportunity!\",\n",
    "                    \"Please review the attached document and provide feedback\",\n",
    "                    \"HOT SINGLES in your area! Chat now!\",\n",
    "                    \"The project deadline has been extended to next week\",\n",
    "                    \"PHARMACY ONLINE - Best prices guaranteed!\",\n",
    "                    \"Thanks for your help with the presentation\",\n",
    "                    \"ACT NOW! Limited time offer expires soon!\",\n",
    "                    \"Could you please send me your contact details?\",\n",
    "                    \"CASINO BONUS! Free spins available now!\",\n",
    "                    \"Meeting reschedule: New time is 2pm Thursday\",\n",
    "                    \"Weight loss miracle! Lose 30 pounds in 30 days!\",\n",
    "                    \"Please find the monthly report attached\",\n",
    "                    \"CLICK HERE for amazing deals and discounts!\",\n",
    "                    \"Let me know if you need any assistance\",\n",
    "                    \"Nigerian prince needs your help transferring money\",\n",
    "                    \"The weather forecast shows rain for tomorrow\",\n",
    "                    \"PRIZE ALERT! You've been selected as a winner!\",\n",
    "                    \"Can we schedule a call to discuss the project?\",\n",
    "                    \"ADULT CONTENT! 18+ only! Click here now!\",\n",
    "                    \"Thank you for your order. Delivery expected in 3 days\"\n",
    "                ],\n",
    "                'label': [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
    "            }\n",
    "            df = pd.DataFrame(sample_data)\n",
    "            print(\"Using sample dataset for demonstration\")\n",
    "        else:\n",
    "            # Load actual dataset\n",
    "            df = pd.read_csv(file_path)\n",
    "            print(f\"Loaded dataset with {len(df)} rows\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def train(self, df):\n",
    "        \"\"\"\n",
    "        Train the spam detection model\n",
    "        \"\"\"\n",
    "        print(\"\\n=== TRAINING SPAM DETECTION MODEL ===\")\n",
    "        \n",
    "        # Data overview\n",
    "        print(f\"\\nDataset shape: {df.shape}\")\n",
    "        print(f\"Spam emails: {sum(df['label'])}\")\n",
    "        print(f\"Ham emails: {len(df) - sum(df['label'])}\")\n",
    "        \n",
    "        # Preprocess text data\n",
    "        print(\"\\nPreprocessing text data...\")\n",
    "        df['processed_text'] = df['text'].apply(self.preprocess_text)\n",
    "        \n",
    "        # Prepare features and target\n",
    "        X = df['processed_text']\n",
    "        y = df['label']\n",
    "        \n",
    "        # Train-test split (70-30)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        print(f\"Training set size: {len(X_train)}\")\n",
    "        print(f\"Test set size: {len(X_test)}\")\n",
    "        \n",
    "        # TF-IDF Vectorization\n",
    "        print(\"\\nApplying TF-IDF vectorization...\")\n",
    "        X_train_tfidf = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_tfidf = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        print(f\"Feature dimensions: {X_train_tfidf.shape[1]}\")\n",
    "        \n",
    "        # Train logistic regression model\n",
    "        print(\"\\nTraining Logistic Regression model...\")\n",
    "        self.model.fit(X_train_tfidf, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.model.predict(X_test_tfidf)\n",
    "        y_pred_proba = self.model.predict_proba(X_test_tfidf)\n",
    "        \n",
    "        # Store results for evaluation\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.y_pred_proba = y_pred_proba\n",
    "        \n",
    "        print(\"Model training completed!\")\n",
    "        \n",
    "        return X_train_tfidf, X_test_tfidf, y_train, y_test, y_pred\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        \"\"\"\n",
    "        Comprehensive model evaluation\n",
    "        \"\"\"\n",
    "        print(\"\\n=== MODEL EVALUATION ===\")\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(self.y_test, self.y_pred)\n",
    "        precision = precision_score(self.y_test, self.y_pred)\n",
    "        recall = recall_score(self.y_test, self.y_pred)\n",
    "        f1 = f1_score(self.y_test, self.y_pred)\n",
    "        \n",
    "        print(f\"\\nPerformance Metrics:\")\n",
    "        print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall:    {recall:.4f}\")\n",
    "        print(f\"F1 Score:  {f1:.4f}\")\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(f\"\\nDetailed Classification Report:\")\n",
    "        print(classification_report(self.y_test, self.y_pred, \n",
    "                                  target_names=['Ham', 'Spam']))\n",
    "        \n",
    "        return accuracy, precision, recall, f1\n",
    "    \n",
    "    def plot_confusion_matrix(self):\n",
    "        \"\"\"\n",
    "        Plot confusion matrix\n",
    "        \"\"\"\n",
    "        cm = confusion_matrix(self.y_test, self.y_pred)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Ham', 'Spam'], \n",
    "                   yticklabels=['Ham', 'Spam'])\n",
    "        plt.title('Confusion Matrix - Spam Detection')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.show()\n",
    "        \n",
    "        return cm\n",
    "    \n",
    "    def get_important_features(self, top_n=20):\n",
    "        \"\"\"\n",
    "        Get most important features for spam detection\n",
    "        \"\"\"\n",
    "        print(f\"\\n=== TOP {top_n} FEATURES FOR SPAM DETECTION ===\")\n",
    "        \n",
    "        # Get feature names and coefficients\n",
    "        feature_names = self.vectorizer.get_feature_names_out()\n",
    "        coefficients = self.model.coef_[0]\n",
    "        \n",
    "        # Create feature importance dataframe\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'coefficient': coefficients,\n",
    "            'abs_coefficient': np.abs(coefficients)\n",
    "        }).sort_values('abs_coefficient', ascending=False)\n",
    "        \n",
    "        print(\"\\nTop spam indicators (positive coefficients):\")\n",
    "        spam_features = feature_importance[feature_importance['coefficient'] > 0].head(top_n//2)\n",
    "        for idx, row in spam_features.iterrows():\n",
    "            print(f\"  {row['feature']}: {row['coefficient']:.4f}\")\n",
    "        \n",
    "        print(\"\\nTop ham indicators (negative coefficients):\")\n",
    "        ham_features = feature_importance[feature_importance['coefficient'] < 0].head(top_n//2)\n",
    "        for idx, row in ham_features.iterrows():\n",
    "            print(f\"  {row['feature']}: {row['coefficient']:.4f}\")\n",
    "        \n",
    "        return feature_importance\n",
    "    \n",
    "    def predict_single_email(self, email_text):\n",
    "        \"\"\"\n",
    "        Predict if a single email is spam or not\n",
    "        \"\"\"\n",
    "        # Preprocess the email\n",
    "        processed_email = self.preprocess_text(email_text)\n",
    "        \n",
    "        # Vectorize\n",
    "        email_tfidf = self.vectorizer.transform([processed_email])\n",
    "        \n",
    "        # Predict\n",
    "        prediction = self.model.predict(email_tfidf)[0]\n",
    "        probability = self.model.predict_proba(email_tfidf)[0]\n",
    "        \n",
    "        result = {\n",
    "            'prediction': 'SPAM' if prediction == 1 else 'HAM',\n",
    "            'spam_probability': probability[1],\n",
    "            'ham_probability': probability[0],\n",
    "            'confidence': max(probability)\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "\n",
    "# Main execution\n",
    "def main():\n",
    "    print(\"SPAM EMAIL DETECTION USING LOGISTIC REGRESSION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Initialize detector\n",
    "    detector = SpamDetector()\n",
    "    \n",
    "    # Load and prepare data\n",
    "    df = detector.load_and_prepare_data(use_sample=True)\n",
    "    \n",
    "    # Train the model\n",
    "    X_train_tfidf, X_test_tfidf, y_train, y_test, y_pred = detector.train(df)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy, precision, recall, f1 = detector.evaluate_model()\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = detector.plot_confusion_matrix()\n",
    "    \n",
    "    # Get important features\n",
    "    feature_importance = detector.get_important_features(top_n=20)\n",
    "    \n",
    "    # Test with custom emails\n",
    "    print(\"\\n=== TESTING WITH CUSTOM EMAILS ===\")\n",
    "    \n",
    "    test_emails = [\n",
    "        \"Congratulations! You've won $10,000! Click here immediately!\",\n",
    "        \"Hi John, can we schedule a meeting for tomorrow?\",\n",
    "        \"URGENT: Your account will be closed! Verify now!\",\n",
    "        \"Thanks for the great presentation yesterday.\"\n",
    "    ]\n",
    "    \n",
    "    for i, email in enumerate(test_emails, 1):\n",
    "        result = detector.predict_single_email(email)\n",
    "        print(f\"\\nTest Email {i}: {email[:50]}...\")\n",
    "        print(f\"Prediction: {result['prediction']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.4f}\")\n",
    "        print(f\"Spam Probability: {result['spam_probability']:.4f}\")\n",
    "    \n",
    "    # Model insights and improvements\n",
    "    print(\"\\n=== MODEL INSIGHTS AND IMPROVEMENTS ===\")\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(\"1. The model successfully identifies spam patterns\")\n",
    "    print(\"2. Common spam words include: free, winner, urgent, click\")\n",
    "    print(\"3. Ham emails typically contain normal conversational language\")\n",
    "    \n",
    "    print(\"\\nPossible Improvements:\")\n",
    "    print(\"1. Use larger, more diverse datasets\")\n",
    "    print(\"2. Try ensemble methods (Random Forest, Gradient Boosting)\")\n",
    "    print(\"3. Implement feature engineering (email metadata, sender patterns)\")\n",
    "    print(\"4. Use advanced NLP techniques (word embeddings, BERT)\")\n",
    "    print(\"5. Regular model retraining with new spam patterns\")\n",
    "    \n",
    "    return detector, accuracy, precision, recall, f1\n",
    "\n",
    "# Run the main function\n",
    "if __name__ == \"__main__\":\n",
    "    detector, accuracy, precision, recall, f1 = main()\n",
    "    \n",
    "    print(f\"\\n=== FINAL RESULTS ===\")\n",
    "    print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(\"Project completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
